import grpc
from concurrent import futures
import time

import ai_pb2
import ai_pb2_grpc

from sam import load_sam_model, process_image_bytes

MAX_MESSAGE_LENGTH = 20 * 1024 * 1024  # 20MB ã«å¢—ã‚„ã™ãªã©

class AIService(ai_pb2_grpc.AIServiceServicer):
    def __init__(self):
        print("ğŸ§  SAM ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        self.gen = load_sam_model()
        print("âœ… ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†")

    def Process(self, request, context):
        print(f"ğŸ“¥ å—ä¿¡")
        result_bytes = process_image_bytes(request.input, self.gen)
        print(f"å‡¦ç†å®Œäº†")
        return ai_pb2.ProcessImageResponse(processed_image=result_bytes, mime_type="image/png")
    
def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10),
                         options=[
                             ("grpc.max_receive_message_length", MAX_MESSAGE_LENGTH),
                             ("grpc.max_send_message_length", MAX_MESSAGE_LENGTH)])
    ai_pb2_grpc.add_AIServiceServicer_to_server(AIService(), server)

    port = 50051
    server.add_insecure_port(f'[::]:{port}')
    server.start()
    print(f"ğŸš€ gRPCã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­... ãƒãƒ¼ãƒˆ: {port}")
    try:
        while True:
            time.sleep(86400)  # ã‚µãƒ¼ãƒãƒ¼ã‚’å¸¸ã«ç¶­æŒ
    except KeyboardInterrupt:
        print("ğŸ›‘ ã‚µãƒ¼ãƒãƒ¼åœæ­¢")
        server.stop(0)


if __name__ == '__main__':
    serve()